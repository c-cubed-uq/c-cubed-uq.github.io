<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>C3</title>

    <!--  =====  SCRIPTS  =====  -->
    <script>

        function updateInteractive_unc(unc_class) {
            var task = document.getElementById("interative-menu-" + unc_class + "-unc").value;

            var carousel = document.getElementById("results-carousel-" + unc_class + "-unc")

            // update the relevant elements
            const values = ["low", "high"]

            // update the relevant elements
            for (const val of values) {
                // ground-truth
                if (unc_class === "epistemic") {
                    var videos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_run_gt");
                    videos.forEach(video => {
                        video.src = "./static/videos/overviews/" + unc_class + "_unc/" + task + "/gt_" + val + "_run.mp4"
                        video.poster = "./static/thumbnails/overviews/" + unc_class + "_unc/" + task + "/gt_" + val + "_run.jpg"
                    });
                };

                for (let t_idx = 0; t_idx < 2; t_idx++) {
                    // update element
                    var videos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_run_" + t_idx);
                    videos.forEach(video => {
                        video.src = "./static/videos/overviews/" + unc_class + "_unc/" + task + "/" + val + "_run_" + t_idx + ".mp4"
                        video.poster = "./static/thumbnails/overviews/" + unc_class + "_unc/" + task + "/" + val + "_run_" + t_idx + ".jpg"
                    });
                };

            };

            // update the text annotation

            for (const val of values) {
                // set display to none
                var text = carousel.querySelectorAll(".text_" + unc_class + "_unc_" + val);
                text.forEach(text => {
                    text.style.display = "none";
                });

                // enable display
                var text = carousel.querySelectorAll("#text_" + unc_class + "_unc_" + val + "_" + task);
                text.forEach(text => {
                    text.style.display = "inline-block";
                });
            };

        }

        function updateInteractive_bridge_hallucination(unc_class) {
            var task = document.getElementById("interative-menu-" + unc_class + "-annotated" + "-unc").value;

            var carousel = document.getElementById("results-carousel-" + unc_class + "-annotated" + "-unc")

            // update the function parameter
            unc_class = unc_class + "_annotated"

            // update the relevant elements
            const values = ["low", "med", "high"]

            // map uncertainty level to sample letter in markup
            const sampleLetter = { "low": "a", "med": "b", "high": "c" }

            // update the relevant elements
            for (const val of values) {
                const letter = sampleLetter[val];

                // ground-truth
                var videos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_gt");
                videos.forEach(video => {
                    video.src = "./static/videos/experiments/" + task + "/" + letter + "/rgb.mp4"
                    video.poster = "./static/thumbnails/experiments/" + task + "/" + letter + "/rgb.jpg"
                });

                // generated / composited / map (indices may be 0 only in markup, but loop is safe)
                for (let t_idx = 0; t_idx < 3; t_idx++) {
                    // generated
                    var genVideos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_generated_" + t_idx);
                    genVideos.forEach(video => {
                        video.src = "./static/videos/experiments/" + task + "/" + letter + "/conf_thresh_0.9.mp4"
                        video.poster = "./static/thumbnails/experiments/" + task + "/" + letter + "/conf_thresh_0.9.jpg"
                    });

                    // composited
                    var compVideos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_composited_" + t_idx);
                    compVideos.forEach(video => {
                        video.src = "./static/videos/experiments/" + task + "/" + letter + "/composited_pred_conf_gen_video_conf_thresh_0.9.mp4"
                        video.poster = "./static/thumbnails/experiments/" + task + "/" + letter + "/composited_pred_conf_gen_video_conf_thresh_0.9.jpg"
                    });

                    // uncertainty map
                    var mapVideos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_map_" + t_idx);
                    mapVideos.forEach(video => {
                        video.src = "./static/videos/experiments/" + task + "/" + letter + "/pred_conf_gen_video_conf_thresh_0.9.mp4"
                        video.poster = "./static/thumbnails/experiments/" + task + "/" + letter + "/pred_conf_gen_video_conf_thresh_0.9.jpg"
                    });
                };
            };


        }

        function updateInteractive_decompose_unc(unc_class) {
            var task = document.getElementById("interative-menu-" + unc_class + "-unc").value;

            var carousel = document.getElementById("results-carousel-" + unc_class + "-unc")

            // update the relevant elements
            const values = ["low", "med", "high"]

            // ground-truth 
            for (const val of values) {
                // update element
                var videos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_gt");

                console.log("./static/thumbnails/experiments/decomposition/" + task + "/ground_truth/" + val + "_unc.jpg")

                videos.forEach(video => {
                    video.src = "./static/videos/experiments/decomposition/" + task + "/ground_truth/" + val + "_unc.mp4"
                    video.poster = "./static/thumbnails/experiments/decomposition/" + task + "/ground_truth/" + val + "_unc.jpg"
                });
            };

            // generated videos
            for (let t_idx = 0; t_idx < 3; t_idx++) {

                for (const val of values) {
                    // update element
                    var videos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_generated_" + t_idx);
                    videos.forEach(video => {
                        video.src = "./static/videos/experiments/decomposition/" + task + "/generated/" + val + "_unc_" + t_idx + ".mp4"
                        video.poster = "./static/thumbnails/experiments/decomposition/" + task + "/generated/" + val + "_unc_" + t_idx + ".jpg"
                    });
                };

            };

            // update the text annotation
            for (const val of values) {
                // update element
                // set display to none
                var text = carousel.querySelectorAll(".text_" + unc_class + "_unc_" + val + "_gt");
                text.forEach(text => {
                    text.style.display = "none";
                });
            };

            // enable display
            for (const val of values) {
                // update element
                var text = carousel.querySelectorAll("#text_" + unc_class + "_unc_" + val + "_gt_" + task);
                text.forEach(text => {
                    text.style.display = "inline-block";
                });
            };

        }


    </script>

    <!--  =====  FONTS & ICONS  =====  -->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" />
    <link rel="icon" href="./static/assets/icon.png" />

    <!--  =====  CSS  =====  -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css" />

    <style>
        /* --- GLOBAL --- */
        body {
            background: #fff;
            font-family: "Noto Sans", sans-serif;
            font-size: 16px;
            line-height: 1.5;
            color: #333;
        }

        section {
            padding: 2.5rem 0;
        }

        /* --- SECTION COLORS --- */
        .section-gray {
            background: #f7f7f7;
        }

        /* --- TYPOGRAPHY & LINKS --- */
        .task-title {
            margin-bottom: 1rem;
            font-weight: 600;
        }

        .publication-authors {
            margin-bottom: 1rem;
        }

        /* space below authors */
        .publication-authors a {
            color: #3273dc;
            text-decoration: none;
            white-space: nowrap;
        }

        .publication-authors a:hover {
            text-decoration: underline;
        }

        /* --- HERO & SPACING TWEAKS --- */
        .publication-title {
            margin-top: 0.0rem;
            padding-top: 0.0rem;
        }

        .hero {
            padding-top: 0.75rem;
            padding-bottom: 0.5rem;
        }

        /* tighter gap above overview */
        .hero-body {
            padding: 1.5rem;
        }

        #overview.section {
            padding-top: 0.75rem;
        }

        /* tighter gap below hero */
        .publication-links {
            margin-top: 1.5rem;
            margin-bottom: 1.5rem;
        }

        /* gap between authors/icons & icons/logo */
        figure.lab-logo {
            margin-top: 0.75rem;
        }

        /* gap between icons and Princeton logo */
        /* #sim-robot.section{padding-bottom:0.1rem;} gap above simulation section */
        #bibtex.section- {
            padding-top: 0rem;
        }

        /* gap above BibTeX section */

        /* --- SLICK ARROWS --- */
        .slick-prev:before,
        .slick-next:before {
            color: #3273dc;
            font-size: 32px;
        }

        /* --- THUMBNAILS --- */
        .video-thumb {
            cursor: pointer;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            margin: 0 8px;
        }

        .video-thumb video {
            width: 100%;
            height: auto;
            display: block;
        }

        .thumb-video video {
            border-radius: 5px;
        }

        /* --- STAND‑ALONE VIDEOS --- */
        .overview-video,
        .sim-video {
            width: 100%;
            height: auto;
            border-radius: 0;
            box-shadow: none;
            pointer-events: none;
        }

        /* --- LAYOUT HELPERS --- */
        .task-block {
            margin-bottom: 3rem;
        }

        .task-carousel,
        .task-carousel-exp {
            margin-top: 1rem;
        }

        /* --- CONTENT WIDTH CONSISTENCY --- */
        .content-container {
            max-width: 960px;
            margin: 0 auto;
        }

        /* --- PDF EMBED --- */
        .pdf-container {
            margin-top: 1.5rem;
        }

        .pdf-container object {
            width: 100%;
            height: 600px;
            border: none;
        }

        /* --- REAL EXP IMG --- */
        .real-exp-img {
            width: 100%;
            height: auto;
            max-width: 100%;
        }

        /* --- LINK COLOR (lighter blue, closer to default hyperlinks) --- */

        .publication-authors a:hover {
            text-decoration: underline;
        }

        /* --- HERO ↔ OVERVIEW GAP (shrink) --- */
        .hero {
            padding-bottom: 0rem;
        }

        /* was 0.5rem */
        #overview.section {
            padding-top: 0rem;
            padding-bottom: 0rem;
        }

        /* was 0.75rem */

        /* --- REAL-ROBOT ↔ SIMULATION GAP (shrink) --- */
        #real-robot.section {
            padding-top: 2.5rem;
        }

        /* default Bulma ≈2.5rem */
        #real-robot.section {
            padding-bottom: 2.5rem;
        }

        #sim-to-real-1 {
            margin-bottom: 0;
        }

        /* default Bulma ≈2.5rem */
        .rounded-textbox {
            background-color: #ADD8E6;
            /* Light blue background color */
            color: #333;
            /* Dark gray text color */
            padding: 10px;
            /* Space between text and box edges */
            border-radius: 5px;
            /* Rounded corners */
            width: fit-content;
            /* Optional: Set a fixed width */
            text-align: center;
            /* Optional: Center the text */
            box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.2);
            /* Optional: Add a subtle shadow */
        }

        /* default Bulma ≈2.5rem */
        #sim-robot.section {
            padding-top: 2.5rem;
        }

        /* default Bulma ≈2.5rem */


        /* --- SIMULATION ↔ BIBTEX GAP (shrink) --- */
        #BibTeX.section {
            padding-top: 0.1rem;
        }

        /* tighten above BibTeX */
    </style>

    <!--  =====  Latex  =====  -->
    <!-- <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> -->
</head>

<body>

    <!-- ===== HERO with title & authors ===== -->
    <section class="hero section">
        <div class="hero-body">
            <div class="container is-max-widescreen has-text-centered">
                <h1 class="title is-2 publication-title">
                    <div style="display: flex; align-items: center; justify-content: center;">
                        <div style="flex: 0 0 18%; text-align: center;">
                            <img src="static/assets/icon.gif" alt="Icon" style="height: 3.5em; max-width: 100%;">
                        </div>
                        <div style="flex: 0 0 82%; text-align: left;">
                            Continuous Calibrated Controllable <br /> <span style="font-size: xx-large;"> Video
                                Generation </span>
                        </div>
                    </div>
                </h1>

                <!-- ===== AUTHORS (three rows, no underscores) ===== -->
                <div class="is-size-5 publication-authors">
                    <div>
                        <span class="author-block"><a href="https://may0mei.github.io/">Zhiting&nbsp;Mei*</a></span>,
                        <span class="author-block"><a
                                href="https://tenny-yinyijun.github.io/">Tenny&nbsp;Yin</a></span>,
                        <span class="author-block"><a href="#">Micah&nbsp;Baker</a></span>,
                        <span class="author-block"><a href="#">Ola&nbsp;Shorinwa*</a></span>,
                        <span class="author-block"><a
                                href="https://irom-lab.princeton.edu/majumdar/">Anirudha&nbsp;Majumdar</a></span>
                    </div>
                </div>
                <div>
                    <sup>&#42;</sup>Equal Contribution.
                </div>

                <!-- ===== RESOURCE ICONS ===== -->
                <div class="publication-links">
                    <a href="./static/papers/paper.pdf" class="external-link button is-normal is-rounded is-dark"
                        target="_blank" rel="noopener">
                        <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper (Coming Soon!)</span>
                    </a>
                    <a href="#"
                        class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener">
                        <span class="icon"><i class="ai ai-arxiv"></i></span><span>arXiv (Coming Soon!)</span>
                    </a>
                    <!-- <a href="#" class="external-link button is-normal is-rounded is-dark" target="_blank"
                        rel="noopener">
                        <span class="icon"><i class="fab fa-youtube"></i></span><span>Video (Coming Soon!)</span>
                    </a> -->
                    <a href="#"
                        class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener">
                        <span class="icon"><i class="fab fa-github"></i></span><span>Code (Coming Soon!)</span>
                    </a>
                    <!-- <a href="https://huggingface.co/datasets/s-qubed/s-qubed"
                        class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener">
                        <span class="icon"><i class="fa fa-database"></i></span><span>Dataset</span>
                    </a> -->
                </div>

                <!-- ===== LAB LOGO ===== -->

                <figure class="image is-inline-block lab-logo">
                    <img src="static/assets/irom_princeton.png" alt="IROM Lab logo" style="max-width:500px;">
                </figure>

            </div>
        </div>
    </section>

    <!-- ===== OVERVIEW ===== -->
    <section id="overview" class="section">
        <div class="container is-max-desktop content-container has-text-centered">
            <video class="overview-video" autoplay loop muted playsinline
                poster="static/thumbnails/overviews/banner.jpg">
                <source src="static/videos/overviews/banner.mp4" type="video/mp4" />
                Your browser does not support the video tag.
            </video>
            <p style="margin-top:1rem;">
                We present <img src="static/images/architecture/algname.svg" alt="C3"
                    style="display: inline; height: 1em; vertical-align: baseline;">, the first method for
                training continuous-scale calibrated controllable (action-conditioned) video models using
                proper scoring rules to generate dense confidence predictions at the subpatch (channel)
                level that are physically interpretable and aligned with observations.
            </p>
        </div>
    </section>

    <!-- ===== ABSTRACT ===== -->
    <section id="abstract" class="section">
        <div class="container is-max-desktop content-container">
            <h2 class="title is-3 has-text-centered">Abstract</h2>
            <p>
                Recent advances in generative video models have led to significant breakthroughs in high-fidelity video
                synthesis,
                specifically in controllable video generation where the generated video is conditioned on text and
                action inputs.
                This impressive leap in performance has paved the way for broad applications from instruction-guided
                video editing
                to world modeling in robotics.
                Despite these exceptional capabilities, controllable video models often <strong>hallucinate</strong>
                ---generating future video frames that are misaligned with physical reality---which raises serious
                concerns
                in many tasks such as robot policy evaluation and planning. However, state-of-the-art video models lack
                the
                ability to assess and express their confidence, further impeding hallucination mitigation.
                To rigorously address this challenge, we propose <img src="static/images/architecture/algname.svg"
                    alt="C3" style="display: inline; height: 1em; vertical-align: baseline;">,
                an uncertainty quantification method for training <strong>continuous-scale</strong>
                <strong>calibrated</strong> <strong>controllable</strong> video models
                for <strong>dense</strong> confidence estimation at the <strong>subpatch</strong> (channel) level,
                precisely localizing the uncertainty
                in each generated video frame. The effectiveness of our UQ method is underpinned by three core
                innovations:
                First, our method introduces a novel framework that trains video models for <strong>correctness</strong>
                and <strong>calibration</strong>
                via strictly proper scoring rules.
                Second, we estimate the video model's uncertainty in latent space, avoiding training instability and
                prohibitive training
                costs associated with pixel-space approaches.
                Third, we map the dense latent-space uncertainty to <strong>interpretable</strong> pixel-level
                uncertainty in the RGB space for
                intuitive visualization, providing high-resolution uncertainty heatmaps that identify untrustworthy
                regions.
                Through extensive experiments on large-scale robot learning datasets (Bridge and DROID) and real-world
                evaluations,
                we demonstrate that our method not only provides calibrated uncertainty estimates within the training
                distribution,
                but also enables effective out-of-distribution detection.
            </p>
            <!-- <br>
      <video id="summary-video" class="shadow" controls preload="metadata" width="100%" poster="static/thumbnails/talk_video.jpg">
        <source src="static/videos/talk_video.mp4" type="video/mp4" />
        Your browser does not support the video tag.
      </video> -->
        </div>
    </section>

    <!-- ===== Architecture ===== -->
    <section id="architecture" class="section">
        <div class="container is-max-desktop content-container">
            <h2 class="title is-3 has-text-centered">Uncertainty Quantification via <img
                    src="static/images/architecture/algname.svg" alt="C3"
                    style="display: inline; height: 1em; vertical-align: baseline;"></h2>
            <video class="overview-video" autoplay loop muted playsinline
                poster="static/thumbnails/overviews/architecture.jpg">
                <source src="static/videos/overviews/architecture.mp4" type="video/mp4" />
                Your browser does not support the video tag.
            </video>
            <br>
            <p>
                <img src="static/images/architecture/algname.svg" alt="C3" 
                style="display: inline; height: 1em; vertical-align: baseline;">
                enables simultaneous video generation and uncertainty quantification (visualized as a heatmap), 
                quantifying the model's confidence in its accuracy using a UQ probe acting on the video latents.
            </p>
        </div>


    <!-- ===== Experiments ===== -->
    <section id="experiment-results" class="section">
        <div class="container is-max-desktop content-container">
            <h2 class="title is-3 has-text-centered">Experiments</h2>
            <p class="has-text-justified">

            </p>
            <br>

            <!-- ===== Main experiment videos ===== -->
            <div class="task-block" id="q1">
                <h3 class="title is-4 task-title">C3 Videos Highlighting Artifacts</h3>
                <p class="has-text-justified" style="margin-top: 1rem; margin-bottom: 1rem;">

                </p>
                <!-- Result plot-->
                <!-- <img src="./static/images/experiments/metric/rank_correlation.png" class="real-exp-img"
                    alt="Calibration Plot." /> -->


                <div class="columns">
                    <div class="column" style="text-align: center;">
                        <div style="padding-bottom: 15px; padding-top: 5px; display: flex; text-align: left;">
                            <p>
                                We visualize the ground-truth, generated, composited uncertainty, and uncertainty map
                                videos,
                                highlighting the various types of hallucinations of the video model: object
                                appearing/disappearing,
                                distortion, interaction dynamics, and occlusion.
                            </p>
                        </div>
                        <div class="select is-rounded">
                            <select id="interative-menu-human-annotated-unc"
                                onchange="updateInteractive_bridge_hallucination('human')">
                                <option value="0" selected="selected">Object Appearing</option> 
                                <option value="1">Object Disappearing</option>
                                <option value="2">Object Distortion</option>
                                <option value="3">Non-Physical Dynamics</option>
                                <option value="4">Occlusion</option>
                            </select>
                        </div>
                    </div>

                </div>


                <div class="container">
                    <div id="results-carousel-human-annotated-unc" class="carousel results-carousel">

                        <!-- Top labels aligned with four columns -->
                        <div
                            style="display: flex; align-items: center; justify-content: center; gap: 1rem; margin: 0 2rem;">
                            <div class="rounded-textbox"
                                style="flex: 1 1 25%; text-align: center; background-color: #79b5e9; color: black;">
                                Ground-Truth
                            </div>
                            <div class="rounded-textbox"
                                style="flex: 1 1 25%; text-align: center; background-color: #c3a3ec; color: black;">
                                Generated
                            </div>
                            <div class="rounded-textbox"
                                style="flex: 1 1 25%; text-align: center; background-color: #fbacb5; color: black;">
                                Composited
                            </div>
                            <div class="rounded-textbox"
                                style="flex: 1 1 25%; text-align: center; background-color: #a2d56b; color: black;">
                                Uncertainty Maps
                            </div>
                        </div>

                        <!-- <hr> -->

                        <!-- Row for sample a -->
                        <div
                            style="display: flex; align-items: flex-start; justify-content: center; gap: 1rem; margin: 0 2rem; margin-top: 1rem;">
                            <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                <video autoplay loop muted playsinline
                                    poster="./static/thumbnails/experiments/0/a/rgb.jpg" preload="metadata"
                                    class="human_annotated_unc_low_gt" height="100%">
                                    <source src="./static/videos/experiments/0/a/rgb.mp4" type="video/mp4" />
                                </video>
                                <p style="text-align: left;" id="text_human_annotated_unc_low_gt_sample_0"
                                    class="text_human_annotated_unc_low_gt"></p>
                            </div>

                            <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                <video autoplay loop muted playsinline
                                    poster="./static/thumbnails/experiments/0/a/conf_thresh_0.9.jpg" preload="metadata"
                                    class="human_annotated_unc_low_generated_0" height="100%">
                                    <source src="./static/videos/experiments/0/a/conf_thresh_0.9.mp4"
                                        type="video/mp4" />
                                </video>
                            </div>

                            <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                <video autoplay loop muted playsinline
                                    poster="./static/thumbnails/experiments/0/a/composited_pred_conf_gen_video_conf_thresh_0.9.jpg"
                                    preload="metadata" class="human_annotated_unc_low_composited_0" height="100%">
                                    <source
                                        src="./static/videos/experiments/0/a/composited_pred_conf_gen_video_conf_thresh_0.9.mp4"
                                        type="video/mp4" />
                                </video>
                            </div>

                            <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                <video autoplay loop muted playsinline
                                    poster="./static/thumbnails/experiments/0/a/pred_conf_gen_video_conf_thresh_0.9.jpg"
                                    preload="metadata" class="human_annotated_unc_low_map_0" height="100%">
                                    <source
                                        src="./static/videos/experiments/0/a/pred_conf_gen_video_conf_thresh_0.9.mp4"
                                        type="video/mp4" />
                                </video>
                            </div>
                        </div>

                        <!-- Row for sample b -->
                        <div
                            style="display: flex; align-items: flex-start; justify-content: center; gap: 1rem; margin: 0 2rem; margin-top: 1rem;">
                            <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                <video autoplay loop muted playsinline
                                    poster="./static/thumbnails/experiments/0/b/rgb.jpg" preload="metadata"
                                    class="human_annotated_unc_med_gt" height="100%">
                                    <source src="./static/videos/experiments/0/b/rgb.mp4" type="video/mp4" />
                                </video>
                                <p style="text-align: left;" id="text_human_annotated_unc_med_gt_sample_0"
                                    class="text_human_annotated_unc_med_gt"></p>
                            </div>

                            <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                <video autoplay loop muted playsinline
                                    poster="./static/thumbnails/experiments/0/b/conf_thresh_0.9.jpg" preload="metadata"
                                    class="human_annotated_unc_med_generated_0" height="100%">
                                    <source src="./static/videos/experiments/0/b/conf_thresh_0.9.mp4"
                                        type="video/mp4" />
                                </video>
                            </div>

                            <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                <video autoplay loop muted playsinline
                                    poster="./static/thumbnails/experiments/0/b/composited_pred_conf_gen_video_conf_thresh_0.9.jpg"
                                    preload="metadata" class="human_annotated_unc_med_composited_0" height="100%">
                                    <source
                                        src="./static/videos/experiments/0/b/composited_pred_conf_gen_video_conf_thresh_0.9.mp4"
                                        type="video/mp4" />
                                </video>
                            </div>

                            <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                <video autoplay loop muted playsinline
                                    poster="./static/thumbnails/experiments/0/b/pred_conf_gen_video_conf_thresh_0.9.jpg"
                                    preload="metadata" class="human_annotated_unc_med_map_0" height="100%">
                                    <source
                                        src="./static/videos/experiments/0/b/pred_conf_gen_video_conf_thresh_0.9.mp4"
                                        type="video/mp4" />
                                </video>
                            </div>
                        </div>

                        <!-- Row for sample c -->
                        <div
                            style="display: flex; align-items: flex-start; justify-content: center; gap: 1rem; margin: 0 2rem; margin-top: 1rem; margin-bottom: 1rem;">
                            <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                <video autoplay loop muted playsinline
                                    poster="./static/thumbnails/experiments/0/c/rgb.jpg" preload="metadata"
                                    class="human_annotated_unc_high_gt" height="100%">
                                    <source src="./static/videos/experiments/0/c/rgb.mp4" type="video/mp4" />
                                </video>
                                <p style="text-align: left;" id="text_human_annotated_unc_high_gt_sample_0"
                                    class="text_human_annotated_unc_high_gt"></p>
                            </div>

                            <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                <video autoplay loop muted playsinline
                                    poster="./static/thumbnails/experiments/0/c/conf_thresh_0.9.jpg" preload="metadata"
                                    class="human_annotated_unc_high_generated_0" height="100%">
                                    <source src="./static/videos/experiments/0/c/conf_thresh_0.9.mp4"
                                        type="video/mp4" />
                                </video>
                            </div>

                            <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                <video autoplay loop muted playsinline
                                    poster="./static/thumbnails/experiments/0/c/composited_pred_conf_gen_video_conf_thresh_0.9.jpg"
                                    preload="metadata" class="human_annotated_unc_high_composited_0" height="100%">
                                    <source
                                        src="./static/videos/experiments/0/c/composited_pred_conf_gen_video_conf_thresh_0.9.mp4"
                                        type="video/mp4" />
                                </video>
                            </div>

                            <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                <video autoplay loop muted playsinline
                                    poster="./static/thumbnails/experiments/0/c/pred_conf_gen_video_conf_thresh_0.9.jpg"
                                    preload="metadata" class="human_annotated_unc_high_map_0" height="100%">
                                    <source
                                        src="./static/videos/experiments/0/c/pred_conf_gen_video_conf_thresh_0.9.mp4"
                                        type="video/mp4" />
                                </video>
                            </div>
                        </div>

                    </div>
                </div>
            </div>

            <br>


            <!-- ===== DROID Experiments ===== -->
            <div class="task-block" id="q2">
                <h3 class="title is-4 task-title">DROID</h3>
                <p class="has-text-justified" style="margin-top: 1rem; margin-bottom: 1rem;">
                    Droid.
                    <br>
                </p>


            </div>

            <!-- ===== OOD Detection ===== -->
            <div class="task-block" id="q2">
                <h3 class="title is-4 task-title">Detecting Out-of-Distribution Inputs at Inference</h3>
                <p class="has-text-justified" style="margin-top: 1rem; margin-bottom: 1rem;">
                    Here, we explore the performance of C3 in out-of-distribution (OOD) detection at inference time, noting
                    the importance of calibrated uncertainty estimates in reliable OOD detection.
                    <br>
                </p>


            </div>
        </div>
    </section>



    <!-- <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>
@misc{mei2025confidentvideomodelsempowering,
    title={How Confident are Video Models? Empowering Video Models to Express their Uncertainty}, 
    author={Zhiting Mei and Ola Shorinwa and Anirudha Majumdar},
    year={2025},
    eprint={2510.02571},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/2510.02571}, 
}
        </code></pre>
        </div>
    </section> -->


    <br>
    <center class="is-size-10">
        The website design was adapted from <a href="https://nerfies.github.io" class="external-link"><span
                class="dnerf">Nerfies</span></a>.
    </center>
    <br>

    <!-- ===== SCRIPTS ===== -->
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
    <script>
        $(function () {
            // Init carousels (only those still using .task-carousel wrappers)
            $('.task-carousel').slick({
                slidesToShow: 4,
                slidesToScroll: 1,
                infinite: false,
                arrows: true,
                dots: false,
                lazyLoad: 'ondemand',
                touchMove: true,
                responsive: [
                    { breakpoint: 1024, settings: { slidesToShow: 3 } },
                    { breakpoint: 768, settings: { slidesToShow: 2 } },
                    { breakpoint: 480, settings: { slidesToShow: 1 } }
                ]
            });

            // Horizontal track‑pad scroll → carousel navigation; let vertical scroll bubble up
            $('.task-carousel').on('wheel', function (e) {
                const deltaX = e.originalEvent.deltaX;
                const deltaY = e.originalEvent.deltaY;
                if (Math.abs(deltaX) > Math.abs(deltaY)) {
                    e.preventDefault();
                    $(this).slick(deltaX < 0 ? 'slickPrev' : 'slickNext');
                }
            });

            $('.task-carousel-exp').slick({
                slidesToShow: 3,
                slidesToScroll: 1,
                infinite: false,
                arrows: true,
                dots: false,
                lazyLoad: 'ondemand',
                touchMove: true,
                responsive: [
                    { breakpoint: 1024, settings: { slidesToShow: 1 } },
                    { breakpoint: 768, settings: { slidesToShow: 1 } },
                    { breakpoint: 480, settings: { slidesToShow: 1 } }
                ]
            });

            // Horizontal track‑pad scroll → carousel navigation; let vertical scroll bubble up
            $('.task-carousel').on('wheel', function (e) {
                const deltaX = e.originalEvent.deltaX;
                const deltaY = e.originalEvent.deltaY;
                if (Math.abs(deltaX) > Math.abs(deltaY)) {
                    e.preventDefault();
                    $(this).slick(deltaX < 0 ? 'slickPrev' : 'slickNext');
                }
            });
            $('.task-carousel-exp').on('wheel', function (e) {
                const deltaX = e.originalEvent.deltaX;
                const deltaY = e.originalEvent.deltaY;
                if (Math.abs(deltaX) > Math.abs(deltaY)) {
                    e.preventDefault();
                    $(this).slick(deltaX < 0 ? 'slickPrev' : 'slickNext');
                }
            });

        });
    </script>
</body>

</html>