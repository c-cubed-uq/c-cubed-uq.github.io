<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>C3 - Video World Models That Know When They Don't Know</title>

    <!--  =====  SCRIPTS  =====  -->
    <script>

        function updateInteractive_unc(unc_class) {
            var task = document.getElementById("interative-menu-" + unc_class + "-unc").value;

            var carousel = document.getElementById("results-carousel-" + unc_class + "-unc")

            // update the relevant elements
            const values = ["low", "high"]

            // update the relevant elements
            for (const val of values) {
                // ground-truth
                if (unc_class === "epistemic") {
                    var videos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_run_gt");
                    videos.forEach(video => {
                        video.src = "./static/videos/overviews/" + unc_class + "_unc/" + task + "/gt_" + val + "_run.mp4"
                        video.poster = "./static/thumbnails/overviews/" + unc_class + "_unc/" + task + "/gt_" + val + "_run.jpg"
                    });
                };

                for (let t_idx = 0; t_idx < 2; t_idx++) {
                    // update element
                    var videos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_run_" + t_idx);
                    videos.forEach(video => {
                        video.src = "./static/videos/overviews/" + unc_class + "_unc/" + task + "/" + val + "_run_" + t_idx + ".mp4"
                        video.poster = "./static/thumbnails/overviews/" + unc_class + "_unc/" + task + "/" + val + "_run_" + t_idx + ".jpg"
                    });
                };

            };

            // update the text annotation

            for (const val of values) {
                // set display to none
                var text = carousel.querySelectorAll(".text_" + unc_class + "_unc_" + val);
                text.forEach(text => {
                    text.style.display = "none";
                });

                // enable display
                var text = carousel.querySelectorAll("#text_" + unc_class + "_unc_" + val + "_" + task);
                text.forEach(text => {
                    text.style.display = "inline-block";
                });
            };

        }

        function updateInteractive_bridge_hallucination(unc_class) {
            var task = document.getElementById("interative-menu-" + unc_class + "-annotated" + "-unc").value;

            var carousel = document.getElementById("results-carousel-" + unc_class + "-annotated" + "-unc")

            // update the function parameter
            unc_class = unc_class + "_annotated"

            // update the relevant elements
            const values = ["low", "med", "high"]

            // map uncertainty level to sample letter in markup
            const sampleLetter = { "low": "a", "med": "b", "high": "c" }

            // update the relevant elements
            for (const val of values) {
                const letter = sampleLetter[val];

                // ground-truth
                var videos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_gt");
                videos.forEach(video => {
                    video.src = "./static/videos/experiments/bridge/" + task + "/" + letter + "/rgb.mp4"
                    video.poster = "./static/thumbnails/experiments/bridge/" + task + "/" + letter + "/rgb.jpg"
                });

                // generated / composited / map (indices may be 0 only in markup, but loop is safe)
                for (let t_idx = 0; t_idx < 1; t_idx++) {
                    // generated
                    var genVideos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_generated_" + t_idx);
                    genVideos.forEach(video => {
                        video.src = "./static/videos/experiments/bridge/" + task + "/" + letter + "/conf_thresh_0.9.mp4"
                        video.poster = "./static/thumbnails/experiments/bridge/" + task + "/" + letter + "/conf_thresh_0.9.jpg"
                    });

                    // composited
                    var compVideos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_composited_" + t_idx);
                    compVideos.forEach(video => {
                        video.src = "./static/videos/experiments/bridge/" + task + "/" + letter + "/composited_pred_conf_gen_video_conf_thresh_0.9.mp4"
                        video.poster = "./static/thumbnails/experiments/bridge/" + task + "/" + letter + "/composited_pred_conf_gen_video_conf_thresh_0.9.jpg"
                    });

                    // uncertainty map
                    var mapVideos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_map_" + t_idx);
                    mapVideos.forEach(video => {
                        video.src = "./static/videos/experiments/bridge/" + task + "/" + letter + "/pred_conf_gen_video_conf_thresh_0.9.mp4"
                        video.poster = "./static/thumbnails/experiments/bridge/" + task + "/" + letter + "/pred_conf_gen_video_conf_thresh_0.9.jpg"
                    });
                };
            };


        }


        function updateInteractive_droid_hallucination(unc_class) {
            var task = document.getElementById("interative-menu-" + unc_class + "-annotated" + "-unc").value;

            var carousel = document.getElementById("results-carousel-" + unc_class + "-annotated" + "-unc")

            // update the function parameter
            unc_class = unc_class + "_annotated"

            // update the relevant elements
            const values = ["low"]

            // map uncertainty level to sample letter in markup
            const sampleLetter = { "low": "a", "med": "b", "high": "c" }

            // update the relevant elements
            for (const val of values) {
                const letter = sampleLetter[val];

                // ground-truth
                var videos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_gt");
                videos.forEach(video => {
                    video.src = "./static/videos/experiments/droid/" + task + "/" + letter + "/rgb.mp4"
                    video.poster = "./static/thumbnails/experiments/droid/" + task + "/" + letter + "/rgb.jpg"
                });

                // generated / composited / map (indices may be 0 only in markup, but loop is safe)
                for (let t_idx = 0; t_idx < 1; t_idx++) {
                    // generated
                    var genVideos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_generated_" + t_idx);
                    genVideos.forEach(video => {
                        video.src = "./static/videos/experiments/droid/" + task + "/" + letter + "/conf_thresh_0.9.mp4"
                        video.poster = "./static/thumbnails/experiments/droid/" + task + "/" + letter + "/conf_thresh_0.9.jpg"
                    });

                    // composited
                    var compVideos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_composited_" + t_idx);
                    compVideos.forEach(video => {
                        video.src = "./static/videos/experiments/droid/" + task + "/" + letter + "/composited_pred_conf_gen_video_conf_thresh_0.9.mp4"
                        video.poster = "./static/thumbnails/experiments/droid/" + task + "/" + letter + "/composited_pred_conf_gen_video_conf_thresh_0.9.jpg"
                    });

                    // uncertainty map
                    var mapVideos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_map_" + t_idx);
                    mapVideos.forEach(video => {
                        video.src = "./static/videos/experiments/droid/" + task + "/" + letter + "/pred_conf_gen_video_conf_thresh_0.9.mp4"
                        video.poster = "./static/thumbnails/experiments/droid/" + task + "/" + letter + "/pred_conf_gen_video_conf_thresh_0.9.jpg"
                    });
                };
            };


        }


        function updateInteractive_ood_hallucination(unc_class) {
            var task = document.getElementById("interative-menu-" + unc_class + "-annotated" + "-unc").value;

            var carousel = document.getElementById("results-carousel-" + unc_class + "-annotated" + "-unc")

            // update the function parameter
            unc_class = unc_class + "_annotated"

            // update the relevant elements
            const values = ["low", "med"]

            // map uncertainty level to sample letter in markup
            const sampleLetter = { "low": "a", "med": "b", "high": "c" }

            // update the relevant elements
            for (const val of values) {
                const letter = sampleLetter[val];

                // ground-truth
                var videos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_gt");
                videos.forEach(video => {
                    video.src = "./static/videos/experiments/ood/" + task + "/" + letter + "/rgb.mp4"
                    video.poster = "./static/thumbnails/experiments/ood/" + task + "/" + letter + "/rgb.jpg"
                });

                // generated / composited / map (indices may be 0 only in markup, but loop is safe)
                for (let t_idx = 0; t_idx < 1; t_idx++) {
                    // generated
                    var genVideos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_generated_" + t_idx);
                    genVideos.forEach(video => {
                        video.src = "./static/videos/experiments/ood/" + task + "/" + letter + "/conf_thresh_0.600.mp4"
                        video.poster = "./static/thumbnails/experiments/ood/" + task + "/" + letter + "/conf_thresh_0.600.jpg"
                    });

                    // composited
                    var compVideos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_composited_" + t_idx);
                    compVideos.forEach(video => {
                        video.src = "./static/videos/experiments/ood/" + task + "/" + letter + "/composited_pred_conf_gen_video_conf_thresh_0.600.mp4"
                        video.poster = "./static/thumbnails/experiments/ood/" + task + "/" + letter + "/composited_pred_conf_gen_video_conf_thresh_0.600.jpg"
                    });

                    // uncertainty map
                    var mapVideos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_map_" + t_idx);
                    mapVideos.forEach(video => {
                        video.src = "./static/videos/experiments/ood/" + task + "/" + letter + "/pred_conf_gen_video_conf_thresh_0.600.mp4"
                        video.poster = "./static/thumbnails/experiments/ood/" + task + "/" + letter + "/pred_conf_gen_video_conf_thresh_0.600.jpg"
                    });
                };
            };


        }

        function updateInteractive_decompose_unc(unc_class) {
            var task = document.getElementById("interative-menu-" + unc_class + "-unc").value;

            var carousel = document.getElementById("results-carousel-" + unc_class + "-unc")

            // update the relevant elements
            const values = ["low", "med", "high"]

            // ground-truth 
            for (const val of values) {
                // update element
                var videos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_gt");

                console.log("./static/thumbnails/experiments/decomposition/" + task + "/ground_truth/" + val + "_unc.jpg")

                videos.forEach(video => {
                    video.src = "./static/videos/experiments/decomposition/" + task + "/ground_truth/" + val + "_unc.mp4"
                    video.poster = "./static/thumbnails/experiments/decomposition/" + task + "/ground_truth/" + val + "_unc.jpg"
                });
            };

            // generated videos
            for (let t_idx = 0; t_idx < 3; t_idx++) {

                for (const val of values) {
                    // update element
                    var videos = carousel.querySelectorAll("." + unc_class + "_unc_" + val + "_generated_" + t_idx);
                    videos.forEach(video => {
                        video.src = "./static/videos/experiments/decomposition/" + task + "/generated/" + val + "_unc_" + t_idx + ".mp4"
                        video.poster = "./static/thumbnails/experiments/decomposition/" + task + "/generated/" + val + "_unc_" + t_idx + ".jpg"
                    });
                };

            };

            // update the text annotation
            for (const val of values) {
                // update element
                // set display to none
                var text = carousel.querySelectorAll(".text_" + unc_class + "_unc_" + val + "_gt");
                text.forEach(text => {
                    text.style.display = "none";
                });
            };

            // enable display
            for (const val of values) {
                // update element
                var text = carousel.querySelectorAll("#text_" + unc_class + "_unc_" + val + "_gt_" + task);
                text.forEach(text => {
                    text.style.display = "inline-block";
                });
            };

        }


    </script>

    <!--  =====  FONTS & ICONS  =====  -->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" />
    <link rel="icon" href="./static/assets/icon.png" />

    <!--  =====  CSS  =====  -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick-theme.min.css" />

    <style>
        /* --- GLOBAL --- */
        body {
            background: #fff;
            font-family: "Noto Sans", sans-serif;
            font-size: 16px;
            line-height: 1.5;
            color: #333;
        }

        section {
            padding: 2.5rem 0;
        }

        /* --- SECTION COLORS --- */
        .section-gray {
            background: #f7f7f7;
        }

        /* --- TYPOGRAPHY & LINKS --- */
        .task-title {
            margin-bottom: 1rem;
            font-weight: 600;
        }

        .publication-authors {
            margin-bottom: 1rem;
        }

        /* space below authors */
        .publication-authors a {
            color: #3273dc;
            text-decoration: none;
            white-space: nowrap;
        }

        .publication-authors a:hover {
            text-decoration: underline;
        }

        /* --- HERO & SPACING TWEAKS --- */
        .publication-title {
            margin-top: 0.0rem;
            padding-top: 0.0rem;
        }

        .hero {
            padding-top: 0.75rem;
            padding-bottom: 0.5rem;
        }

        /* tighter gap above overview */
        .hero-body {
            padding: 1.5rem;
        }

        #overview.section {
            padding-top: 0.75rem;
        }

        /* tighter gap below hero */
        .publication-links {
            margin-top: 1.5rem;
            margin-bottom: 1.5rem;
        }

        /* gap between authors/icons & icons/logo */
        figure.lab-logo {
            margin-top: 0.75rem;
        }

        /* gap between icons and Princeton logo */
        /* #sim-robot.section{padding-bottom:0.1rem;} gap above simulation section */
        #bibtex.section- {
            padding-top: 0rem;
        }

        /* gap above BibTeX section */

        /* --- SLICK ARROWS --- */
        .slick-prev:before,
        .slick-next:before {
            color: #3273dc;
            font-size: 32px;
        }

        /* --- THUMBNAILS --- */
        .video-thumb {
            cursor: pointer;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            margin: 0 8px;
        }

        .video-thumb video {
            width: 100%;
            height: auto;
            display: block;
        }

        .thumb-video video {
            border-radius: 5px;
        }

        /* --- STAND‑ALONE VIDEOS --- */
        .overview-video,
        .sim-video {
            width: 100%;
            height: auto;
            border-radius: 0;
            box-shadow: none;
            pointer-events: none;
        }

        /* --- LAYOUT HELPERS --- */
        .task-block {
            margin-bottom: 3rem;
        }

        .task-carousel,
        .task-carousel-exp {
            margin-top: 1rem;
        }

        /* --- CONTENT WIDTH CONSISTENCY --- */
        .content-container {
            max-width: 960px;
            margin: 0 auto;
        }

        /* --- PDF EMBED --- */
        .pdf-container {
            margin-top: 1.5rem;
        }

        .pdf-container object {
            width: 100%;
            height: 600px;
            border: none;
        }

        /* --- REAL EXP IMG --- */
        .real-exp-img {
            width: 100%;
            height: auto;
            max-width: 100%;
        }

        /* --- LINK COLOR (lighter blue, closer to default hyperlinks) --- */

        .publication-authors a:hover {
            text-decoration: underline;
        }

        /* --- HERO ↔ OVERVIEW GAP (shrink) --- */
        .hero {
            padding-bottom: 0rem;
        }

        /* was 0.5rem */
        #overview.section {
            padding-top: 0rem;
            padding-bottom: 0rem;
        }

        /* was 0.75rem */

        /* --- REAL-ROBOT ↔ SIMULATION GAP (shrink) --- */
        #real-robot.section {
            padding-top: 2.5rem;
        }

        /* default Bulma ≈2.5rem */
        #real-robot.section {
            padding-bottom: 2.5rem;
        }

        #sim-to-real-1 {
            margin-bottom: 0;
        }

        /* default Bulma ≈2.5rem */
        .rounded-textbox {
            background-color: #ADD8E6;
            /* Light blue background color */
            color: #333;
            /* Dark gray text color */
            padding: 10px;
            /* Space between text and box edges */
            border-radius: 5px;
            /* Rounded corners */
            width: fit-content;
            /* Optional: Set a fixed width */
            text-align: center;
            /* Optional: Center the text */
            box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.2);
            /* Optional: Add a subtle shadow */
        }

        /* default Bulma ≈2.5rem */
        #sim-robot.section {
            padding-top: 2.5rem;
        }

        /* default Bulma ≈2.5rem */


        /* --- SIMULATION ↔ BIBTEX GAP (shrink) --- */
        #BibTeX.section {
            padding-top: 0.1rem;
        }

        /* tighten above BibTeX */
    </style>

    <!--  =====  Latex  =====  -->
    <!-- <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script> -->
    <!-- <script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>
    <script type="text/javascript"
        src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        </script> -->
</head>

<body>

    <!-- ===== HERO with title & authors ===== -->
    <section class="hero section">
        <div class="hero-body">
            <div class="container is-max-widescreen has-text-centered">
                <h1 class="title is-2 publication-title">
                    <div style="display: flex; align-items: center; justify-content: center;">
                        <div style="flex: 0 0 18%; text-align: center;">
                            <img src="static/assets/icon.gif" alt="Icon" style="height: 3.5em; max-width: 100%;">
                        </div>
                        <div style="flex: 0 0 82%; text-align: left;">
                            <!-- <img src="static/images/architecture/algname.svg" alt="C3"
                                style="display: inline; height: 1em; vertical-align: baseline;"> -->
                            World Models That Know When They Don't Know:
                            <br /> <span style="font-size: xx-large;">Controllable Video Generation with Calibrated
                                Uncertainty
                            </span>
                            <!-- Continuous Calibrated Controllable <br /> <span style="font-size: xx-large;"> Video Generation </span> -->
                        </div>
                    </div>
                </h1>

                <!-- ===== AUTHORS (three rows, no underscores) ===== -->
                <div class="is-size-5 publication-authors">
                    <div>
                        <span class="author-block"><a href="https://may0mei.github.io/">Zhiting&nbsp;Mei*</a></span>,
                        <span class="author-block"><a
                                href="https://tenny-yinyijun.github.io/">Tenny&nbsp;Yin</a></span>,
                        <span class="author-block"><a href="#">Micah&nbsp;Baker</a></span>,
                        <span class="author-block"><a href="#">Ola&nbsp;Shorinwa*</a></span>,
                        <span class="author-block"><a
                                href="https://irom-lab.princeton.edu/majumdar/">Anirudha&nbsp;Majumdar</a></span>
                    </div>
                </div>
                <div>
                    <sup>&#42;</sup>Equal Contribution.
                </div>

                <!-- ===== RESOURCE ICONS ===== -->
                <div class="publication-links">
                    <a href="./static/papers/paper.pdf" class="external-link button is-normal is-rounded is-dark"
                        target="_blank" rel="noopener">
                        <span class="icon"><i class="fas fa-file-pdf"></i></span><span>Paper (Coming Soon!)</span>
                    </a>
                    <a href="#" class="external-link button is-normal is-rounded is-dark" target="_blank"
                        rel="noopener">
                        <span class="icon"><i class="ai ai-arxiv"></i></span><span>arXiv (Coming Soon!)</span>
                    </a>
                    <!-- <a href="#" class="external-link button is-normal is-rounded is-dark" target="_blank"
                        rel="noopener">
                        <span class="icon"><i class="fab fa-youtube"></i></span><span>Video (Coming Soon!)</span>
                    </a> -->
                    <a href="https://github.com/irom-princeton/c-cubed"
                        class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener">
                        <span class="icon"><i class="fab fa-github"></i></span><span>Code</span>
                    </a>
                    <!-- <a href="https://huggingface.co/datasets/s-qubed/s-qubed"
                        class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener">
                        <span class="icon"><i class="fa fa-database"></i></span><span>Dataset</span>
                    </a> -->
                </div>

                <!-- ===== LAB LOGO ===== -->

                <figure class="image is-inline-block lab-logo">
                    <img src="static/assets/irom_princeton.png" alt="IROM Lab logo" style="max-width:500px;">
                </figure>

            </div>
        </div>
    </section>

    <!-- ===== OVERVIEW ===== -->
    <section id="overview" class="section">
        <div class="container is-max-desktop content-container has-text-centered">
            <video class="overview-video" autoplay loop muted playsinline
                poster="static/thumbnails/overviews/banner.jpg">
                <source src="static/videos/overviews/banner.mp4" type="video/mp4" />
                Your browser does not support the video tag.
            </video>
            <p style="margin-top:1rem;">
                We present
                <!-- $C^{3}$, -->
                <img src="static/images/architecture/algname.svg" alt="C3"
                    style="display: inline; height: 1em; vertical-align: baseline;">,
                the first method for
                training video world models <strong>that know when they don't know</strong>
                <br>
                for
                continuous-scale calibrated controllable video synthesis.
                Using proper scoring rules,
                <img src="static/images/architecture/algname.svg" alt="C3"
                    style="display: inline; height: 1em; vertical-align: baseline;">
                generates dense confidence
                predictions at the subpatch (channel)
                level that are physically interpretable and aligned with observations.
            </p>
        </div>
    </section>

    <!-- ===== ABSTRACT ===== -->
    <section id="abstract" class="section">
        <div class="container is-max-desktop content-container">
            <h2 class="title is-3 has-text-centered">Abstract</h2>
            <p>
                Recent advances in generative video models have led to significant breakthroughs in high-fidelity video
                synthesis,
                specifically in controllable video generation where the generated video is conditioned on text and
                action inputs.
                This impressive leap in performance has paved the way for broad applications from instruction-guided
                video editing
                to world modeling in robotics.
                Despite these exceptional capabilities, controllable video models often
                <strong>hallucinate</strong>&mdash;generating future video frames that are misaligned with physical
                reality&mdash;which raises
                serious
                concerns
                in many tasks such as robot policy evaluation and planning. However, state-of-the-art video models lack
                the
                ability to assess and express their confidence, further impeding hallucination mitigation.
                To rigorously address this challenge, we propose
                <!-- $C^{3}$ -->
                <img src="static/images/architecture/algname.svg" alt="C3"
                    style="display: inline; height: 1em; vertical-align: baseline;">,
                an uncertainty quantification method for training <strong>continuous-scale</strong>
                <strong>calibrated</strong> <strong>controllable</strong> video models
                for <strong>dense</strong> confidence estimation at the <strong>subpatch</strong> (channel) level,
                precisely localizing the uncertainty
                in each generated video frame. The effectiveness of our UQ method is underpinned by three core
                innovations:
                First, our method introduces a novel framework that trains video models for <strong>correctness</strong>
                and <strong>calibration</strong>
                via strictly proper scoring rules.
                Second, we estimate the video model's uncertainty in latent space, avoiding training instability and
                prohibitive training
                costs associated with pixel-space approaches.
                Third, we map the dense latent-space uncertainty to <strong>interpretable</strong> pixel-level
                uncertainty in the RGB space for
                intuitive visualization, providing high-resolution uncertainty heatmaps that identify untrustworthy
                regions.
                Through extensive experiments on large-scale robot learning datasets (Bridge and DROID) and real-world
                evaluations,
                we demonstrate that our method not only provides calibrated uncertainty estimates within the training
                distribution,
                but also enables effective out-of-distribution detection.
            </p>
            <!-- <br>
      <video id="summary-video" class="shadow" controls preload="metadata" width="100%" poster="static/thumbnails/talk_video.jpg">
        <source src="static/videos/talk_video.mp4" type="video/mp4" />
        Your browser does not support the video tag.
      </video> -->
        </div>
    </section>

    <!-- ===== Architecture ===== -->
    <section id="architecture" class="section">
        <div class="container is-max-desktop content-container">
            <h2 class="title is-3 has-text-centered">Training Video Models to Express their Uncertainty via
                <!-- $C^{3}$ -->
                <img src="static/images/architecture/algname.svg" alt="C3"
                    style="display: inline; height: 1em; vertical-align: baseline;">
            </h2>
            <video class="overview-video" autoplay loop muted playsinline
                poster="static/thumbnails/overviews/architecture.jpg">
                <source src="static/videos/overviews/architecture.mp4" type="video/mp4" />
                Your browser does not support the video tag.
            </video>
            <br>
            <p>
                <!-- $C^{3}$ -->
                <img src="static/images/architecture/algname.svg" alt="C3"
                    style="display: inline; height: 1em; vertical-align: baseline;">
                enables simultaneous video generation and uncertainty quantification,
                expressing dense estimates of the model's confidence in the accuracy of each subpatch
                in the generated video.
                The resulting uncertainty estimates localize potentially untrustworthy regions of the generated video.
                We design a transformer-based uncertainty quantification probe
                <!-- <img src="static/images/architecture/conf_probe.svg" alt="f_theta"
                    style="display: inline; height: 1em; vertical-align: baseline;"> -->
                integrated within the video generation pipeline
                <!-- $f_{\theta}$ -->
                to estimate the video model’s
                confidence
                directly in latent space.
                This design choice provides a highly-expressive, flexible framework for training video models
                efficiently.
                To demonstrate the generality of our approach across different model architectures,
                we train (i) fixed-scale classification, (ii) multi-class classification,
                and (iii) continuous-scale classification models using proper scoring rules and empirically show
                calibration
                across different test scenarios.
                <br>
                <br>
                Our method provides <strong>dense interpretable</strong> visualizations
                of the video model's confidence using a confidence heatmap, which
                transforms the model's confidence predictions to the RGB color space using a color
                map. The red regions of the heatmap highlight areas of <em>high uncertainty</em>,
                corresponding to locations where the model is unsure if the
                generated video matches the ground-truth video.
                In contrast, the blue and green regions represent areas of <em>high confidence</em>
                where the model is highly confident about the <em>accuracy</em> (blue areas)
                or <em>inaccuracy</em> (green areas) of the generated video.
            </p>
        </div>


        <!-- ===== Experiments ===== -->
        <section id="experiment-results" class="section">
            <div class="container is-max-desktop content-container">
                <h2 class="title is-3 has-text-centered">Experiments</h2>
                <p class="has-text-justified">
                    We conduct experiments on the Bridge and DROID datasets, examining the
                    calibration and interpretability of our method in a broad variety of tasks
                    via the following questions:
                </p>
                <br>

                <!-- ===== Interpretability videos ===== -->
                <div class="task-block" id="q1">
                    <h3 class="title is-4 task-title">
                        Are
                        <img src="static/images/architecture/algname.svg" alt="C3"
                            style="display: inline; height: 1em; vertical-align: baseline;">
                        uncertainty estimates interpretable?
                    </h3>
                    <p class="has-text-justified" style="margin-top: 1rem; margin-bottom: 1rem;">
                        <img src="static/images/architecture/algname.svg" alt="C3"
                            style="display: inline; height: 1em; vertical-align: baseline;">
                        produces interpretable uncertainty estimates that are well-calibrated.
                        Here, we provide visualizations of the dense confidence heatmaps computed by our method,
                        showing alignment between the estimated uncertainty and accuracy of the
                        generated videos qualitatively.
                        Notably, as the deviation of the generated video from the ground-truth increases,
                        the video model's uncertainty also increases, which is
                        indicated by the greater intensity of the red region in the heatmaps temporally.
                    </p>
                    <!-- Result plot-->
                    <!-- <img src="./static/images/experiments/metric/rank_correlation.png" class="real-exp-img"
                    alt="Calibration Plot." /> -->

                    <div class="container">
                        <div id="results-carousel-interpretability-annotated-unc" class="carousel results-carousel">

                            <!-- Top labels aligned with four columns -->
                            <div
                                style="display: flex; align-items: center; justify-content: center; gap: 1rem; margin: 0 2rem;">
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #79b5e9; color: black;">
                                    Ground-Truth
                                </div>
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #c3a3ec; color: black;">
                                    Generated
                                </div>
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #fbacb5; color: black;">
                                    Composited
                                </div>
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #a2d56b; color: black;">
                                    Uncertainty Maps
                                </div>
                            </div>

                            <!-- <hr> -->

                            <!-- Row for sample a -->
                            <div
                                style="display: flex; align-items: flex-start; justify-content: center; gap: 1rem; margin: 0 2rem; margin-top: 1rem;">
                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/a/rgb.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_low_gt" height="100%">
                                        <source src="./static/videos/experiments/interpretability/0/a/rgb.mp4"
                                            type="video/mp4" />
                                    </video>
                                    <p style="text-align: left;"
                                        id="text_interpretability_annotated_unc_low_gt_sample_0"
                                        class="text_interpretability_annotated_unc_low_gt"></p>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/a/conf_thresh_1.0.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_low_generated_0"
                                        height="100%">
                                        <source
                                            src="./static/videos/experiments/interpretability/0/a/conf_thresh_1.0.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/a/composited_pred_conf_gen_video_conf_thresh_1.0.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_low_composited_0"
                                        height="100%">
                                        <source
                                            src="./static/videos/experiments/interpretability/0/a/composited_pred_conf_gen_video_conf_thresh_1.0.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/a/pred_conf_gen_video_conf_thresh_1.0.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_low_map_0"
                                        height="100%">
                                        <source
                                            src="./static/videos/experiments/interpretability/0/a/pred_conf_gen_video_conf_thresh_1.0.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>
                            </div>

                            <!-- Row for sample b -->
                            <div
                                style="display: flex; align-items: flex-start; justify-content: center; gap: 1rem; margin: 0 2rem; margin-top: 1rem;">
                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/b/rgb.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_med_gt" height="100%">
                                        <source src="./static/videos/experiments/interpretability/0/b/rgb.mp4"
                                            type="video/mp4" />
                                    </video>
                                    <p style="text-align: left;"
                                        id="text_interpretability_annotated_unc_med_gt_sample_0"
                                        class="text_interpretability_annotated_unc_med_gt"></p>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/b/conf_thresh_1.0.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_med_generated_0"
                                        height="100%">
                                        <source
                                            src="./static/videos/experiments/interpretability/0/b/conf_thresh_1.0.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/b/composited_pred_conf_gen_video_conf_thresh_1.0.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_med_composited_0"
                                        height="100%">
                                        <source
                                            src="./static/videos/experiments/interpretability/0/b/composited_pred_conf_gen_video_conf_thresh_1.0.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/b/pred_conf_gen_video_conf_thresh_1.0.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_med_map_0"
                                        height="100%">
                                        <source
                                            src="./static/videos/experiments/interpretability/0/b/pred_conf_gen_video_conf_thresh_1.0.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>
                            </div>

                            <!-- Row for sample c -->
                            <div
                                style="display: flex; align-items: flex-start; justify-content: center; gap: 1rem; margin: 0 2rem; margin-top: 1rem; margin-bottom: 1rem;">
                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/c/rgb.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_high_gt" height="100%">
                                        <source src="./static/videos/experiments/interpretability/0/c/rgb.mp4"
                                            type="video/mp4" />
                                    </video>
                                    <p style="text-align: left;"
                                        id="text_interpretability_annotated_unc_high_gt_sample_0"
                                        class="text_interpretability_annotated_unc_high_gt"></p>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/c/conf_thresh_1.0.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_high_generated_0"
                                        height="100%">
                                        <source
                                            src="./static/videos/experiments/interpretability/0/c/conf_thresh_1.0.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/c/composited_pred_conf_gen_video_conf_thresh_1.0.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_high_composited_0"
                                        height="100%">
                                        <source
                                            src="./static/videos/experiments/interpretability/0/c/composited_pred_conf_gen_video_conf_thresh_1.0.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/c/pred_conf_gen_video_conf_thresh_1.0.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_high_map_0"
                                        height="100%">
                                        <source
                                            src="./static/videos/experiments/interpretability/0/c/pred_conf_gen_video_conf_thresh_1.0.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>
                            </div>

                            <!-- Row for sample d -->
                            <div
                                style="display: flex; align-items: flex-start; justify-content: center; gap: 1rem; margin: 0 2rem; margin-top: 1rem; margin-bottom: 1rem;">
                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/d/rgb.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_high_gt" height="100%">
                                        <source src="./static/videos/experiments/interpretability/0/d/rgb.mp4"
                                            type="video/mp4" />
                                    </video>
                                    <p style="text-align: left;"
                                        id="text_interpretability_annotated_unc_high_gt_sample_0"
                                        class="text_interpretability_annotated_unc_high_gt"></p>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/d/conf_thresh_1.0.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_high_generated_0"
                                        height="100%">
                                        <source
                                            src="./static/videos/experiments/interpretability/0/d/conf_thresh_1.0.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/d/composited_pred_conf_gen_video_conf_thresh_1.0.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_high_composited_0"
                                        height="100%">
                                        <source
                                            src="./static/videos/experiments/interpretability/0/d/composited_pred_conf_gen_video_conf_thresh_1.0.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/interpretability/0/d/pred_conf_gen_video_conf_thresh_1.0.jpg"
                                        preload="metadata" class="interpretability_annotated_unc_high_map_0"
                                        height="100%">
                                        <source
                                            src="./static/videos/experiments/interpretability/0/d/pred_conf_gen_video_conf_thresh_1.0.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>
                            </div>

                        </div>
                    </div>

                </div>





                <!-- ===== Main Hallucination videos ===== -->
                <div class="task-block" id="q2">
                    <h3 class="title is-4 task-title">
                        Can
                        <img src="static/images/architecture/algname.svg" alt="C3"
                            style="display: inline; height: 1em; vertical-align: baseline;">
                        detect hallucinations?
                    </h3>
                    <p class="has-text-justified" style="margin-top: 1rem; margin-bottom: 1rem;">

                    </p>
                    <!-- Result plot-->
                    <!-- <img src="./static/images/experiments/metric/rank_correlation.png" class="real-exp-img"
                     alt="Calibration Plot." /> -->


                    <div class="columns">
                        <div class="column" style="text-align: center;">
                            <div style="padding-bottom: 15px; padding-top: 5px; display: flex; text-align: left;">
                                <p>
                                    <img src="static/images/architecture/algname.svg" alt="C3"
                                        style="display: inline; height: 1em; vertical-align: baseline;">
                                    produces
                                    interpretable, calibrated uncertainty estimates at a <strong>fine-grained</strong>
                                    level,
                                    capturing
                                    non-confident regions of the video which contain hallucinations,
                                    such as object appearing and disappearing, distortions, physically-inconsistent
                                    interaction dynamics, and occlusions.
                                    For example, our method identifies areas with inaccurate blurry background,
                                    rigid object deformation or enlogation, and uncertainty due to unobservable
                                    properties, e.g., mass, friction, etc.
                                    Here, we visualize the ground-truth, generated, composited uncertainty, and
                                    uncertainty heatmap
                                    videos, highlighting the effectiveness of
                                    <img src="static/images/architecture/algname.svg" alt="C3"
                                        style="display: inline; height: 1em; vertical-align: baseline;">
                                    on the Bridge and DROID datasets.
                                </p>
                            </div>

                            <!-- ===== Bridge Experiments ===== -->
                            <h4 class="title is-5 task-title" style="text-align: left; margin-bottom: 0;">Bridge
                                Experiments
                            </h4>

                            <div class="select is-rounded">
                                <select id="interative-menu-bridge-annotated-unc"
                                    onchange="updateInteractive_bridge_hallucination('bridge')">
                                    <option value="0" selected="selected">Object Appearing</option>
                                    <option value="1">Object Disappearing</option>
                                    <option value="2">Object Distortion</option>
                                    <option value="3">Non-Physical Dynamics</option>
                                    <option value="4">Occlusion</option>
                                </select>
                            </div>
                        </div>

                    </div>


                    <div class="container">
                        <div id="results-carousel-bridge-annotated-unc" class="carousel results-carousel">

                            <!-- Top labels aligned with four columns -->
                            <div
                                style="display: flex; align-items: center; justify-content: center; gap: 1rem; margin: 0 2rem;">
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #79b5e9; color: black;">
                                    Ground-Truth
                                </div>
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #c3a3ec; color: black;">
                                    Generated
                                </div>
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #fbacb5; color: black;">
                                    Composited
                                </div>
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #a2d56b; color: black;">
                                    Uncertainty Maps
                                </div>
                            </div>

                            <!-- <hr> -->

                            <!-- Row for sample a -->
                            <div
                                style="display: flex; align-items: flex-start; justify-content: center; gap: 1rem; margin: 0 2rem; margin-top: 1rem;">
                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/bridge/0/a/rgb.jpg" preload="metadata"
                                        class="bridge_annotated_unc_low_gt" height="100%">
                                        <source src="./static/videos/experiments/bridge/0/a/rgb.mp4" type="video/mp4" />
                                    </video>
                                    <p style="text-align: left;" id="text_bridge_annotated_unc_low_gt_sample_0"
                                        class="text_bridge_annotated_unc_low_gt"></p>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/bridge/0/a/conf_thresh_0.9.jpg"
                                        preload="metadata" class="bridge_annotated_unc_low_generated_0" height="100%">
                                        <source src="./static/videos/experiments/bridge/0/a/conf_thresh_0.9.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/bridge/0/a/composited_pred_conf_gen_video_conf_thresh_0.9.jpg"
                                        preload="metadata" class="bridge_annotated_unc_low_composited_0" height="100%">
                                        <source
                                            src="./static/videos/experiments/bridge/0/a/composited_pred_conf_gen_video_conf_thresh_0.9.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/bridge/0/a/pred_conf_gen_video_conf_thresh_0.9.jpg"
                                        preload="metadata" class="bridge_annotated_unc_low_map_0" height="100%">
                                        <source
                                            src="./static/videos/experiments/bridge/0/a/pred_conf_gen_video_conf_thresh_0.9.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>
                            </div>

                            <!-- Row for sample b -->
                            <div
                                style="display: flex; align-items: flex-start; justify-content: center; gap: 1rem; margin: 0 2rem; margin-top: 1rem;">
                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/bridge/0/b/rgb.jpg" preload="metadata"
                                        class="bridge_annotated_unc_med_gt" height="100%">
                                        <source src="./static/videos/experiments/bridge/0/b/rgb.mp4" type="video/mp4" />
                                    </video>
                                    <p style="text-align: left;" id="text_bridge_annotated_unc_med_gt_sample_0"
                                        class="text_bridge_annotated_unc_med_gt"></p>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/bridge/0/b/conf_thresh_0.9.jpg"
                                        preload="metadata" class="bridge_annotated_unc_med_generated_0" height="100%">
                                        <source src="./static/videos/experiments/bridge/0/b/conf_thresh_0.9.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/bridge/0/b/composited_pred_conf_gen_video_conf_thresh_0.9.jpg"
                                        preload="metadata" class="bridge_annotated_unc_med_composited_0" height="100%">
                                        <source
                                            src="./static/videos/experiments/bridge/0/b/composited_pred_conf_gen_video_conf_thresh_0.9.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/bridge/0/b/pred_conf_gen_video_conf_thresh_0.9.jpg"
                                        preload="metadata" class="bridge_annotated_unc_med_map_0" height="100%">
                                        <source
                                            src="./static/videos/experiments/bridge/0/b/pred_conf_gen_video_conf_thresh_0.9.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>
                            </div>

                            <!-- Row for sample c -->
                            <div
                                style="display: flex; align-items: flex-start; justify-content: center; gap: 1rem; margin: 0 2rem; margin-top: 1rem; margin-bottom: 1rem;">
                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/bridge/0/c/rgb.jpg" preload="metadata"
                                        class="bridge_annotated_unc_high_gt" height="100%">
                                        <source src="./static/videos/experiments/bridge/0/c/rgb.mp4" type="video/mp4" />
                                    </video>
                                    <p style="text-align: left;" id="text_bridge_annotated_unc_high_gt_sample_0"
                                        class="text_bridge_annotated_unc_high_gt"></p>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/bridge/0/c/conf_thresh_0.9.jpg"
                                        preload="metadata" class="bridge_annotated_unc_high_generated_0" height="100%">
                                        <source src="./static/videos/experiments/bridge/0/c/conf_thresh_0.9.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/bridge/0/c/composited_pred_conf_gen_video_conf_thresh_0.9.jpg"
                                        preload="metadata" class="bridge_annotated_unc_high_composited_0" height="100%">
                                        <source
                                            src="./static/videos/experiments/bridge/0/c/composited_pred_conf_gen_video_conf_thresh_0.9.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/bridge/0/c/pred_conf_gen_video_conf_thresh_0.9.jpg"
                                        preload="metadata" class="bridge_annotated_unc_high_map_0" height="100%">
                                        <source
                                            src="./static/videos/experiments/bridge/0/c/pred_conf_gen_video_conf_thresh_0.9.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>
                            </div>

                        </div>
                    </div>



                    <hr>

                    <div class="columns">
                        <div class="column" style="text-align: center;">
                            <!-- ===== DROID Experiments ===== -->
                            <h4 class="title is-5 task-title" style="text-align: left; margin-bottom: 0;">DROID
                                Experiments</h4>

                            <div class="select is-rounded">
                                <select id="interative-menu-droid-annotated-unc"
                                    onchange="updateInteractive_droid_hallucination('droid')">
                                    <option value="0" selected="selected">Object Appearing</option>
                                    <option value="1">Object Disappearing</option>
                                    <option value="2">Object Distortion</option>
                                    <option value="3">Non-Physical Dynamics</option>
                                    <!-- <option value="4">Occlusion</option> -->
                                </select>
                            </div>
                        </div>

                    </div>



                    <div class="container">
                        <div id="results-carousel-droid-annotated-unc" class="carousel results-carousel">

                            <!-- Top labels aligned with four columns -->
                            <div
                                style="display: flex; align-items: center; justify-content: center; gap: 1rem; margin: 0 2rem;">
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #79b5e9; color: black;">
                                    Ground-Truth
                                </div>
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #c3a3ec; color: black;">
                                    Generated
                                </div>
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #fbacb5; color: black;">
                                    Composited
                                </div>
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #a2d56b; color: black;">
                                    Uncertainty Maps
                                </div>
                            </div>

                            <!-- <hr> -->

                            <!-- Row for sample a -->
                            <div
                                style="display: flex; align-items: flex-start; justify-content: center; gap: 1rem; margin: 0 2rem; margin-top: 1rem;">
                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/droid/0/a/rgb.jpg" preload="metadata"
                                        class="droid_annotated_unc_low_gt" height="100%">
                                        <source src="./static/videos/experiments/droid/0/a/rgb.mp4" type="video/mp4" />
                                    </video>
                                    <p style="text-align: left;" id="text_droid_annotated_unc_low_gt_sample_0"
                                        class="text_droid_annotated_unc_low_gt"></p>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/droid/0/a/conf_thresh_0.9.jpg"
                                        preload="metadata" class="droid_annotated_unc_low_generated_0" height="100%">
                                        <source src="./static/videos/experiments/droid/0/a/conf_thresh_0.9.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/droid/0/a/composited_pred_conf_gen_video_conf_thresh_0.9.jpg"
                                        preload="metadata" class="droid_annotated_unc_low_composited_0" height="100%">
                                        <source
                                            src="./static/videos/experiments/droid/0/a/composited_pred_conf_gen_video_conf_thresh_0.9.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/droid/0/a/pred_conf_gen_video_conf_thresh_0.9.jpg"
                                        preload="metadata" class="droid_annotated_unc_low_map_0" height="100%">
                                        <source
                                            src="./static/videos/experiments/droid/0/a/pred_conf_gen_video_conf_thresh_0.9.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>
                            </div>
                            <hr>

                        </div>
                    </div>
                </div>

                <br>

                <!-- ===== DROID Experiments ===== -->
                <!-- <div class="task-block" id="q2">
                    <h3 class="title is-4 task-title">
                        Can
                        <img src="static/images/architecture/algname.svg" alt="C3"
                            style="display: inline; height: 1em; vertical-align: baseline;">
                        detect hallucinations?
                    </h3>
                    <p class="has-text-justified" style="margin-top: 1rem; margin-bottom: 1rem;">
                        Droid.
                        <br>
                    </p>


                </div> -->

                <!-- ===== OOD Detection ===== -->
                <div class="task-block" id="q3">
                    <h3 class="title is-4 task-title">Can
                        <img src="static/images/architecture/algname.svg" alt="C3"
                            style="display: inline; height: 1em; vertical-align: baseline;">
                        detect Out-of-Distribution Inputs at Inference?
                    </h3>
                    <!-- <p class="has-text-justified" style="margin-top: 1rem; margin-bottom: 1rem;">
                        </p> -->

                    <div class="columns">
                        <div class="column" style="text-align: center;">
                            <div style="padding-bottom: 15px; padding-top: 5px; display: flex; text-align: left;">
                                <p>
                                    Here, we explore the performance of
                                    <img src="static/images/architecture/algname.svg" alt="C3"
                                        style="display: inline; height: 1em; vertical-align: baseline;">
                                    in out-of-distribution (OOD) detection at
                                    inference
                                    time,noting the importance of calibrated uncertainty estimates in reliable OOD
                                    detection.
                                    We consider OOD conditions across five axes:
                                    background; lighting; environment clutter; target object
                                    (task); and robot end-effector, creating environment
                                    settings that are noticeably different from those seen
                                    in the Bridge dataset.
                                    Under these conditions, we see that the video model struggles to generate
                                    accurate videos,
                                    with an observable degradation in the video quality over time.
                                    Despite the distribution shift, our method captures the increasing
                                    uncertainty of the video model, both spatially and temporally.
                                </p>
                            </div>

                            <!-- ===== OOD Experiments ===== -->
                            <div class="select is-rounded">
                                <select id="interative-menu-ood-annotated-unc"
                                    onchange="updateInteractive_ood_hallucination('ood')">
                                    <option value="0" selected="selected">Background</option>
                                    <option value="1">Lighting</option>
                                    <option value="2">Clutter</option>
                                    <option value="3">Target object</option>
                                    <option value="4">End-effector</option>
                                </select>
                            </div>
                        </div>

                    </div>


                    <div class="container">
                        <div id="results-carousel-ood-annotated-unc" class="carousel results-carousel">

                            <!-- Top labels aligned with four columns -->
                            <div
                                style="display: flex; align-items: center; justify-content: center; gap: 1rem; margin: 0 2rem;">
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #79b5e9; color: black;">
                                    Ground-Truth
                                </div>
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #c3a3ec; color: black;">
                                    Generated
                                </div>
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #fbacb5; color: black;">
                                    Composited
                                </div>
                                <div class="rounded-textbox"
                                    style="flex: 1 1 25%; text-align: center; background-color: #a2d56b; color: black;">
                                    Uncertainty Maps
                                </div>
                            </div>

                            <!-- <hr> -->

                            <!-- Row for sample a -->
                            <div
                                style="display: flex; align-items: flex-start; justify-content: center; gap: 1rem; margin: 0 2rem; margin-top: 1rem;">
                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/ood/0/a/rgb.jpg" preload="metadata"
                                        class="ood_annotated_unc_low_gt" height="100%">
                                        <source src="./static/videos/experiments/ood/0/a/rgb.mp4" type="video/mp4" />
                                    </video>
                                    <p style="text-align: left;" id="text_ood_annotated_unc_low_gt_sample_0"
                                        class="text_ood_annotated_unc_low_gt"></p>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/ood/0/a/conf_thresh_0.600.jpg"
                                        preload="metadata" class="ood_annotated_unc_low_generated_0" height="100%">
                                        <source src="./static/videos/experiments/ood/0/a/conf_thresh_0.600.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/ood/0/a/composited_pred_conf_gen_video_conf_thresh_0.600.jpg"
                                        preload="metadata" class="ood_annotated_unc_low_composited_0" height="100%">
                                        <source
                                            src="./static/videos/experiments/ood/0/a/composited_pred_conf_gen_video_conf_thresh_0.600.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/ood/0/a/pred_conf_gen_video_conf_thresh_0.600.jpg"
                                        preload="metadata" class="ood_annotated_unc_low_map_0" height="100%">
                                        <source
                                            src="./static/videos/experiments/ood/0/a/pred_conf_gen_video_conf_thresh_0.600.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>
                            </div>

                            <!-- Row for sample b -->
                            <div
                                style="display: flex; align-items: flex-start; justify-content: center; gap: 1rem; margin: 0 2rem; margin-top: 1rem;">
                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/ood/0/b/rgb.jpg" preload="metadata"
                                        class="ood_annotated_unc_med_gt" height="100%">
                                        <source src="./static/videos/experiments/ood/0/b/rgb.mp4" type="video/mp4" />
                                    </video>
                                    <p style="text-align: left;" id="text_ood_annotated_unc_med_gt_sample_0"
                                        class="text_ood_annotated_unc_med_gt"></p>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/ood/0/b/conf_thresh_0.600.jpg"
                                        preload="metadata" class="ood_annotated_unc_med_generated_0" height="100%">
                                        <source src="./static/videos/experiments/ood/0/b/conf_thresh_0.600.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/ood/0/b/composited_pred_conf_gen_video_conf_thresh_0.600.jpg"
                                        preload="metadata" class="ood_annotated_unc_med_composited_0" height="100%">
                                        <source
                                            src="./static/videos/experiments/ood/0/b/composited_pred_conf_gen_video_conf_thresh_0.600.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>

                                <div class="thumb-video" style="flex: 1 1 25%; text-align: center;">
                                    <video autoplay loop muted playsinline
                                        poster="./static/thumbnails/experiments/ood/0/b/pred_conf_gen_video_conf_thresh_0.600.jpg"
                                        preload="metadata" class="ood_annotated_unc_med_map_0" height="100%">
                                        <source
                                            src="./static/videos/experiments/ood/0/b/pred_conf_gen_video_conf_thresh_0.600.mp4"
                                            type="video/mp4" />
                                    </video>
                                </div>
                            </div>
                        </div>
                    </div>


                </div>

                <br>

            </div>
        </section>



        <!-- <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>
@misc{mei2025confidentvideomodelsempowering,
    title={How Confident are Video Models? Empowering Video Models to Express their Uncertainty}, 
    author={Zhiting Mei and Ola Shorinwa and Anirudha Majumdar},
    year={2025},
    eprint={2510.02571},
    archivePrefix={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/2510.02571}, 
}
        </code></pre>
        </div>
    </section> -->


        <br>
        <center class="is-size-10">
            The website design was adapted from <a href="https://nerfies.github.io" class="external-link"><span
                    class="dnerf">Nerfies</span></a>.
        </center>
        <br>

        <!-- ===== SCRIPTS ===== -->
        <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/slick-carousel/1.8.1/slick.min.js"></script>
        <script>
            $(function () {
                // Init carousels (only those still using .task-carousel wrappers)
                $('.task-carousel').slick({
                    slidesToShow: 4,
                    slidesToScroll: 1,
                    infinite: false,
                    arrows: true,
                    dots: false,
                    lazyLoad: 'ondemand',
                    touchMove: true,
                    responsive: [
                        { breakpoint: 1024, settings: { slidesToShow: 3 } },
                        { breakpoint: 768, settings: { slidesToShow: 2 } },
                        { breakpoint: 480, settings: { slidesToShow: 1 } }
                    ]
                });

                // Horizontal track‑pad scroll → carousel navigation; let vertical scroll bubble up
                $('.task-carousel').on('wheel', function (e) {
                    const deltaX = e.originalEvent.deltaX;
                    const deltaY = e.originalEvent.deltaY;
                    if (Math.abs(deltaX) > Math.abs(deltaY)) {
                        e.preventDefault();
                        $(this).slick(deltaX < 0 ? 'slickPrev' : 'slickNext');
                    }
                });

                $('.task-carousel-exp').slick({
                    slidesToShow: 3,
                    slidesToScroll: 1,
                    infinite: false,
                    arrows: true,
                    dots: false,
                    lazyLoad: 'ondemand',
                    touchMove: true,
                    responsive: [
                        { breakpoint: 1024, settings: { slidesToShow: 1 } },
                        { breakpoint: 768, settings: { slidesToShow: 1 } },
                        { breakpoint: 480, settings: { slidesToShow: 1 } }
                    ]
                });

                // Horizontal track‑pad scroll → carousel navigation; let vertical scroll bubble up
                $('.task-carousel').on('wheel', function (e) {
                    const deltaX = e.originalEvent.deltaX;
                    const deltaY = e.originalEvent.deltaY;
                    if (Math.abs(deltaX) > Math.abs(deltaY)) {
                        e.preventDefault();
                        $(this).slick(deltaX < 0 ? 'slickPrev' : 'slickNext');
                    }
                });
                $('.task-carousel-exp').on('wheel', function (e) {
                    const deltaX = e.originalEvent.deltaX;
                    const deltaY = e.originalEvent.deltaY;
                    if (Math.abs(deltaX) > Math.abs(deltaY)) {
                        e.preventDefault();
                        $(this).slick(deltaX < 0 ? 'slickPrev' : 'slickNext');
                    }
                });

            });
        </script>
</body>

</html>